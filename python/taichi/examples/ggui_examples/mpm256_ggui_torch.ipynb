{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ed914-be4b-42a1-a98e-64d05ff856ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pdb\n",
    "import taichi as ti\n",
    "import pickle\n",
    "from numbers import Number\n",
    "import os, sys\n",
    "import time\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "arch = ti.vulkan if ti._lib.core.with_vulkan() else ti.cuda\n",
    "ti.init(arch=arch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c8fba-8270-4ac4-aa71-3412806d315c",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12176387-ad8b-4866-8133-9e044eedc42e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def arg_parse():\n",
    "    def str2bool(v):\n",
    "        \"\"\"used for argparse, 'type=str2bool', so that can pass in string True or False.\"\"\"\n",
    "        if isinstance(v, bool):\n",
    "            return v\n",
    "        if v.lower() in ('true'):\n",
    "            return True\n",
    "        elif v.lower() in ('false'):\n",
    "            return False\n",
    "        else:\n",
    "            raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Taichi argparse.')\n",
    "    # Experiment management:\n",
    "    parser.add_argument('--gravity_amp', type=float,\n",
    "                        help='Gravity amplitude')\n",
    "    parser.add_argument('--max_n_part_fluid', type=int,\n",
    "                        help='Maximum number of fluid particles')\n",
    "    parser.add_argument('--n_part_particle', type=int,\n",
    "                        help='Number of particles')\n",
    "    parser.add_argument('--n_grid', type=int,\n",
    "                        help='Grid size. E.g. --n_grid=256 means the 2D space is 256x256.')\n",
    "    parser.add_argument('--n_steps', type=int,\n",
    "                        help='Number of simulation steps')\n",
    "    parser.add_argument('--is_particle', type=str2bool, nargs='?', const=True, default=True,\n",
    "                        help=\"If True, will include particle\")\n",
    "    parser.add_argument('--is_gui', type=str2bool, nargs='?', const=True, default=False,\n",
    "                        help='If True, will use GUI.')\n",
    "    parser.add_argument('--n_simu', type=int,\n",
    "                        help='Number of trajectories')\n",
    "    parser.add_argument('--epsilon', type=float,\n",
    "                        help='Threshold for grid_m')\n",
    "    parser.add_argument('--height', type=float,\n",
    "                        help='Maximum height of the fluid.')\n",
    "    parser.add_argument('--gpuid', type=str,\n",
    "                        help='GPU ID.')\n",
    "    parser.add_argument('--is_save', type=str2bool, nargs='?', const=True, default=True,\n",
    "                        help='If True, will use GUI.')\n",
    "\n",
    "    parser.set_defaults(\n",
    "        gravity_amp=2,\n",
    "        max_n_part_fluid=30000,\n",
    "        n_part_particle=1000,\n",
    "        n_grid=128,\n",
    "        n_steps=200,\n",
    "        is_particle=True,\n",
    "        is_gui=False,\n",
    "        n_simu=500,\n",
    "        epsilon=1e-7,\n",
    "        height=0.25,\n",
    "        is_save=True,\n",
    "        gpuid=\"0\",\n",
    "    )\n",
    "    try:\n",
    "        get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "        args = parser.parse_args([])\n",
    "    except:\n",
    "        args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "args = arg_parse()\n",
    "try:\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    is_jupyter = True\n",
    "    # args.n_simu = 50\n",
    "    args.is_save = False\n",
    "    args.gpuid = \"False\"\n",
    "    args.epsilon=1e-6\n",
    "    sys.path.append(os.path.join(os.path.dirname(\"__file__\"), '..', '..', '..', '..', '..', '..'))\n",
    "    from plasma.pytorch_net.util import plot_matrices, pload, pdump\n",
    "except:\n",
    "    is_jupyter = False\n",
    "\n",
    "gravity_amp = args.gravity_amp\n",
    "max_n_part_fluid = args.max_n_part_fluid\n",
    "n_part_particle = args.n_part_particle\n",
    "n_grid = args.n_grid\n",
    "n_steps = args.n_steps\n",
    "is_particle = args.is_particle\n",
    "is_gui = args.is_gui\n",
    "n_simu = args.n_simu\n",
    "height = args.height\n",
    "if args.gpuid == \"False\":\n",
    "    device = \"cpu\"\n",
    "else:\n",
    "    device = f\"cuda:{args.gpuid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d8b425-9991-4163-80af-962c45834ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = 1  # Use a larger value for higher-res simulations\n",
    "n_particles, n_grid = 9000 * quality**2, n_grid * quality\n",
    "dx, inv_dx = 1 / n_grid, float(n_grid)\n",
    "dt = 5e-5 / quality\n",
    "p_vol, p_rho = (dx * 0.5)**2, 1\n",
    "p_mass = p_vol * p_rho\n",
    "E, nu = 5e3, 0.2  # Young's modulus and Poisson's ratio\n",
    "mu_0, lambda_0 = E / (2 * (1 + nu)), E * nu / (\n",
    "    (1 + nu) * (1 - 2 * nu))  # Lame parameters\n",
    "\n",
    "# x = ti.Vector.field(2, dtype=float, shape=n_particles)  # position\n",
    "# v = ti.Vector.field(2, dtype=float, shape=n_particles)  # velocity\n",
    "# C = ti.Matrix.field(2, 2, dtype=float,\n",
    "#                     shape=n_particles)  # affine velocity field\n",
    "# F = ti.Matrix.field(2, 2, dtype=float,\n",
    "#                     shape=n_particles)  # deformation gradient\n",
    "# material = ti.field(dtype=int, shape=n_particles)  # material id\n",
    "# Jp = ti.field(dtype=float, shape=n_particles)  # plastic deformation\n",
    "\n",
    "grid_v = torch.zeros(n_grid, n_grid, 2, device=device, dtype=torch.float64)  # grid node momentum/velocity\n",
    "grid_m = torch.zeros(n_grid, n_grid, device=device, dtype=torch.float64)  # grid node mass\n",
    "gravity = torch.zeros(2, device=device, dtype=torch.float64)\n",
    "attractor_strength = torch.tensor(0., device=device, dtype=torch.float64)\n",
    "attractor_pos = torch.zeros(2, device=device, dtype=torch.float64)\n",
    "\n",
    "# group_size = n_particles // 2\n",
    "# water = ti.Vector.field(2, dtype=float, shape=group_size)  # position\n",
    "# jelly = ti.Vector.field(2, dtype=float, shape=group_size)  # position\n",
    "# snow = ti.Vector.field(2, dtype=float, shape=group_size)  # position\n",
    "# mouse_circle = ti.Vector.field(2, dtype=float, shape=(1, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22db7199-98f0-4f31-aad0-c7bfcd80f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ti.kernel\n",
    "def substep():\n",
    "    # for i, j in grid_m:\n",
    "    #     # gri_v & grid_m: [n_grd, n_grid]\n",
    "    #     grid_v[i, j] = [0, 0]\n",
    "    #     grid_m[i, j] = 0\n",
    "    grid_v.fill_(0)\n",
    "    grid_m.fill_(0)\n",
    "\n",
    "    base = (x * inv_dx - 0.5).long()  # [n_particles] index of the grid\n",
    "    fx = x * inv_dx - base   # [n_particles] location in the grid\n",
    "    # Quadratic kernels  [http://mpm.graphics   Eqn. 123, with x=fx, fx-1,fx-2]\n",
    "    w = [0.5 * (1.5 - fx)**2, 0.75 - (fx - 1)**2, 0.5 * (fx - 0.5)**2]  # [n_particles] \n",
    "    F = (torch.eye(2)[None].expand(n_particles,2,2) + C * dt) @ F\n",
    "    \n",
    "    \n",
    "    for p in x:  # x: [n_particles] Particle state update and scatter to grid (P2G)\n",
    "        base = (x[p] * inv_dx - 0.5).cast(int)  # index of the grid\n",
    "        fx = x[p] * inv_dx - base.cast(float)   # location in the grid\n",
    "        # Quadratic kernels  [http://mpm.graphics   Eqn. 123, with x=fx, fx-1,fx-2]\n",
    "        w = [0.5 * (1.5 - fx)**2, 0.75 - (fx - 1)**2, 0.5 * (fx - 0.5)**2]\n",
    "        # deformation gradient update\n",
    "        F[p] = (ti.Matrix.identity(float, 2) + dt * C[p]) @ F[p]\n",
    "        # Hardening coefficient: snow gets harder when compressed\n",
    "        h = max(0.1, min(5, ti.exp(10 * (1.0 - Jp[p]))))  #   Jp: [n_particles], plastic deformation\n",
    "        if material[p] == 2:  # jelly, make it softer\n",
    "            h = 0.3\n",
    "        mu, la = mu_0 * h, lambda_0 * h\n",
    "        if material[p] == 0:  # liquid\n",
    "            mu = 0.0\n",
    "        U, sig, V = ti.svd(F[p])\n",
    "        J = 1.0\n",
    "        for d in ti.static(range(2)):\n",
    "            new_sig = sig[d, d]\n",
    "            if material[p] == 1:  # Snow\n",
    "                new_sig = min(max(sig[d, d], 1 - 2.5e-2),\n",
    "                              1 + 4.5e-3)  # Plasticity\n",
    "            Jp[p] *= sig[d, d] / new_sig\n",
    "            sig[d, d] = new_sig\n",
    "            J *= new_sig\n",
    "        if material[p] == 0:\n",
    "            # Reset deformation gradient to avoid numerical instability\n",
    "            F[p] = ti.Matrix.identity(float, 2) * ti.sqrt(J)\n",
    "        elif material[p] == 1:\n",
    "            # Reconstruct elastic deformation gradient after plasticity\n",
    "            F[p] = U @ sig @ V.transpose()\n",
    "        stress = 2 * mu * (F[p] - U @ V.transpose()) @ F[p].transpose(\n",
    "        ) + ti.Matrix.identity(float, 2) * la * J * (J - 1)\n",
    "        stress = (-dt * p_vol * 4 * inv_dx * inv_dx) * stress\n",
    "        affine = stress + p_mass * C[p]\n",
    "        # Loop over 3x3 grid node neighborhood\n",
    "        for i, j in ti.static(ti.ndrange(3, 3)):\n",
    "            offset = ti.Vector([i, j])\n",
    "            dpos = (offset.cast(float) - fx) * dx\n",
    "            weight = w[i][0] * w[j][1]\n",
    "            grid_v[base + offset] += weight * (p_mass * v[p] + affine @ dpos)\n",
    "            grid_m[base + offset] += weight * p_mass\n",
    "    for i, j in grid_m:\n",
    "        if grid_m[i, j] > 0:  # No need for epsilon here\n",
    "            grid_v[i,\n",
    "                   j] = (1 / grid_m[i, j]) * grid_v[i,\n",
    "                                                    j]  # Momentum to velocity\n",
    "            grid_v[i, j] += dt * gravity[None] * 30  # gravity\n",
    "            dist = attractor_pos[None] - dx * ti.Vector([i, j])\n",
    "            grid_v[i, j] += dist / (\n",
    "                0.01 + dist.norm()) * attractor_strength[None] * dt * 100\n",
    "            if i < 3 and grid_v[i, j][0] < 0:\n",
    "                grid_v[i, j][0] = 0  # Boundary conditions\n",
    "            if i > n_grid - 3 and grid_v[i, j][0] > 0:\n",
    "                grid_v[i, j][0] = 0\n",
    "            if j < 3 and grid_v[i, j][1] < 0:\n",
    "                grid_v[i, j][1] = 0\n",
    "            if j > n_grid - 3 and grid_v[i, j][1] > 0:\n",
    "                grid_v[i, j][1] = 0\n",
    "    for p in x:  # grid to particle (G2P)\n",
    "        base = (x[p] * inv_dx - 0.5).cast(int)\n",
    "        fx = x[p] * inv_dx - base.cast(float)\n",
    "        w = [0.5 * (1.5 - fx)**2, 0.75 - (fx - 1.0)**2, 0.5 * (fx - 0.5)**2]\n",
    "        new_v = ti.Vector.zero(float, 2)\n",
    "        new_C = ti.Matrix.zero(float, 2, 2)\n",
    "        # loop over 3x3 grid node neighborhood\n",
    "        for i, j in ti.static(ti.ndrange(3, 3)):\n",
    "            dpos = ti.Vector([i, j]).cast(float) - fx\n",
    "            g_v = grid_v[base + ti.Vector([i, j])]\n",
    "            weight = w[i][0] * w[j][1]\n",
    "            new_v += weight * g_v\n",
    "            new_C += 4 * inv_dx * weight * g_v.outer_product(dpos)\n",
    "        v[p], C[p] = new_v, new_C\n",
    "        x[p] += dt * v[p]  # advection\n",
    "\n",
    "\n",
    "@ti.kernel\n",
    "def reset():\n",
    "    for i in range(n_particles):\n",
    "        if i < group_size:\n",
    "            x[i] = [\n",
    "                ti.random() * 1,\n",
    "                ti.random() * 0.2\n",
    "            ]\n",
    "        else:\n",
    "            x[i] = [\n",
    "                ti.random() * 0.2 + 0.3 + 0.10 * (i // group_size),\n",
    "                ti.random() * 0.2 + 0.05 + 0.32 * (i // group_size)\n",
    "            ]\n",
    "        material[i] = i // group_size  # 0: fluid 1: jelly 2: snow\n",
    "        v[i] = [0, 0]\n",
    "        F[i] = ti.Matrix([[1, 0], [0, 1]])\n",
    "        Jp[i] = 1\n",
    "        C[i] = ti.Matrix.zero(float, 2, 2)\n",
    "\n",
    "\n",
    "# @ti.kernel\n",
    "def reset_other_fields(n_particles: int):\n",
    "    material = torch.zeros(n_particles, device=device, dtype=torch.float64)\n",
    "    v = torch.zeros(n_particles, 2, device=device, dtype=torch.float64)\n",
    "    F = torch.tensor([[1, 0], [0, 1]], device=device, dtype=torch.float64)[None].expand(n_particles, 2, 2)\n",
    "    Jp = torch.ones(n_particles, device=device, dtype=torch.float64)\n",
    "    C = torch.zeros(n_particles, 2, 2, device=device, dtype=torch.float64)\n",
    "    return v, C, F, material, Jp\n",
    "\n",
    "\n",
    "# @ti.kernel\n",
    "# def render():\n",
    "#     for i in range(n_particles):\n",
    "#         if i < n_part_particle:\n",
    "#             particle_ti[i] = x[i]\n",
    "#             v_particle_ti[i] = v[i]\n",
    "#         else:\n",
    "#             fluid_ti[i - n_part_particle] = x[i]\n",
    "#             v_fluid_ti[i - n_part_particle] = v[i]\n",
    "\n",
    "def render(x, v, n_part_particle):\n",
    "    particle = x[:n_part_particle]\n",
    "    v_particle = v[:n_part_particle]\n",
    "    fluid = x[n_part_particle:]\n",
    "    v_fluid = v[n_part_particle:]\n",
    "    return particle, v_particle, fluid, v_fluid\n",
    "\n",
    "\n",
    "def sample_shape():\n",
    "    y1 = np.random.rand()*0.05 + 0.01\n",
    "    y2 = np.random.rand()*0.05 + height - 0.05\n",
    "    if np.random.rand() > 0.5:\n",
    "        y1, y2 = y2, y1\n",
    "    shape = [\n",
    "        ((0, y1), (1, y2), 0),\n",
    "    ]\n",
    "    return shape\n",
    "\n",
    "\n",
    "def get_fluid(fluid_shape, n_part, height, epsilon=1e-3):\n",
    "    x_np = np.stack([\n",
    "        np.random.rand(n_part) * (1 - epsilon * 2) + epsilon,\n",
    "        np.random.rand(n_part) * height + epsilon,\n",
    "    ], -1)\n",
    "    lx = x_np[:, 0]\n",
    "    ly = x_np[:, 1]\n",
    "    mask = np.ones(len(x_np)).astype(bool)\n",
    "    for shape_ele in fluid_shape:\n",
    "        (x1, y1), (x2, y2), direction = shape_ele\n",
    "        out = (ly - y1) - (y2 - y1)/(x2 - x1)*(lx - x1)\n",
    "        if direction == 1:\n",
    "            mask_ele = out >= 0\n",
    "        elif direction == 0:\n",
    "            mask_ele = out <= 0\n",
    "        else:\n",
    "            raise\n",
    "        mask = mask & mask_ele\n",
    "    x_fluid = x_np[mask]\n",
    "    return x_fluid\n",
    "\n",
    "\n",
    "def sample_rect_shape():\n",
    "    x1 =  np.random.rand() * 0.2 + 0.1\n",
    "    x2 = -np.random.rand() * 0.2 + 0.9\n",
    "    y1 = np.random.rand() * 0.2 + 0.4\n",
    "    y2 = np.random.rand() * 0.2 + 0.8\n",
    "    rect_shape = (x1, y1), (x2, y2)\n",
    "    return rect_shape\n",
    "\n",
    "\n",
    "def get_particles(rect_shape, n_part):\n",
    "    \"\"\"\n",
    "    lowerleft: (x1, y1)\n",
    "    upperright: (x2, y2)\n",
    "    \"\"\"\n",
    "    (x1, y1), (x2, y2) = rect_shape\n",
    "    lx_np = np.random.rand(n_part, 1) * (x2 - x1) + x1\n",
    "    ly_np = np.random.rand(n_part, 1) * (y2 - y1) + y1\n",
    "    x_np = np.concatenate([lx_np, ly_np], -1)\n",
    "    return x_np\n",
    "\n",
    "def plot_part(x):\n",
    "    import matplotlib.pylab as plt\n",
    "    if not isinstance(x, np.ndarray):\n",
    "        x = x.to_numpy()\n",
    "    plt.plot(x[:,0], x[:,1], \".\")\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def make_dir(filename):\n",
    "    \"\"\"Make directory using filename if the directory does not exist\"\"\"\n",
    "    import os\n",
    "    import errno\n",
    "    if not os.path.exists(os.path.dirname(filename)):\n",
    "        print(\"directory {0} does not exist, created.\".format(os.path.dirname(filename)))\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(filename))\n",
    "        except OSError as exc: # Guard against race condition\n",
    "            if exc.errno != errno.EEXIST:\n",
    "                print(exc)\n",
    "            raise\n",
    "\n",
    "\n",
    "def remove_too_near(x_np, threshold, mode=\"simu\"):\n",
    "    def subfun(x_np):\n",
    "        dist = np.sqrt(((x_np[None] - x_np[:,None]) ** 2).sum(-1))\n",
    "        length = len(dist)\n",
    "        idx = np.arange(length)\n",
    "        dist[idx,idx] = 1\n",
    "        dist_min = dist.min(-1)\n",
    "        idx_sort = np.argsort(dist_min)\n",
    "        return dist_min, idx_sort\n",
    "    length = len(x_np)\n",
    "    if mode == \"seq\":\n",
    "        for i in range(length):\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            dist_min, idx_sort = subfun(x_np)\n",
    "            if dist_min[idx_sort[0]] < threshold:\n",
    "                mask = np.ones(len(x_np)).astype(bool)\n",
    "                mask[idx_sort[0]] = False\n",
    "                x_np = x_np[mask]\n",
    "            else:\n",
    "                break\n",
    "    elif mode == \"simu\":\n",
    "        dist_min, idx_sort = subfun(x_np)\n",
    "        mask = dist_min >= threshold\n",
    "        x_np = x_np[mask]\n",
    "    else:\n",
    "        raise\n",
    "    return x_np\n",
    "\n",
    "\n",
    "def expand_grid(grid, length):\n",
    "    if len(grid.shape) == 3:\n",
    "        n_features = grid.shape[-1]\n",
    "        grid_expand = torch.cat([torch.cat([grid, torch.zeros(n_grid,length,n_features, device=device, dtype=torch.float64)], 1), torch.zeros(length,n_grid+length,n_features, device=device, dtype=torch.float64)], 0)\n",
    "    elif len(grid.shape) == 2:\n",
    "        grid_expand = torch.cat([torch.cat([grid, torch.zeros(n_grid,length, device=device, dtype=torch.float64)], 1), torch.zeros(length,n_grid+length, device=device, dtype=torch.float64)], 0)\n",
    "    else:\n",
    "        raise\n",
    "    return grid_expand\n",
    "\n",
    "\n",
    "def shrink_grid(grid, length):\n",
    "    return grid[:-length, :-length]\n",
    "\n",
    "def to_np_array(*arrays, **kwargs):\n",
    "    array_list = []\n",
    "    for array in arrays:\n",
    "        if array is None:\n",
    "            array_list.append(array)\n",
    "            continue\n",
    "        if isinstance(array, Variable):\n",
    "            if array.is_cuda:\n",
    "                array = array.cpu()\n",
    "            array = array.data\n",
    "        if isinstance(array, torch.Tensor) or isinstance(array, torch.FloatTensor) or isinstance(array, torch.LongTensor) or isinstance(array, torch.ByteTensor) or \\\n",
    "           isinstance(array, torch.cuda.FloatTensor) or isinstance(array, torch.cuda.LongTensor) or isinstance(array, torch.cuda.ByteTensor):\n",
    "            if array.is_cuda:\n",
    "                array = array.cpu()\n",
    "            array = array.numpy()\n",
    "        if isinstance(array, Number):\n",
    "            pass\n",
    "        elif isinstance(array, list) or isinstance(array, tuple):\n",
    "            array = np.array(array)\n",
    "        elif array.shape == (1,):\n",
    "            if \"full_reduce\" in kwargs and kwargs[\"full_reduce\"] is False:\n",
    "                pass\n",
    "            else:\n",
    "                array = array[0]\n",
    "        elif array.shape == ():\n",
    "            array = array.tolist()\n",
    "        array_list.append(array)\n",
    "    if len(array_list) == 1:\n",
    "        if not (\"keep_list\" in kwargs and kwargs[\"keep_list\"]):\n",
    "            array_list = array_list[0]\n",
    "    return array_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05078c5-830a-49bf-82b0-8bfaacca2533",
   "metadata": {},
   "source": [
    "## Functions torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd37d4-82a3-49d9-9f64-c49fcac47d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substep_torch(x, v, C, F, Jp, gravity, epsilon=1e-6):\n",
    "    grid_v = torch.zeros(n_grid, n_grid, 2, device=device, dtype=torch.float64)  # grid node momentum/velocity\n",
    "    grid_m = torch.zeros(n_grid, n_grid, device=device, dtype=torch.float64)  # grid node mass\n",
    "\n",
    "    base = (x * inv_dx - 0.5).long()  # [n_particles] index of the grid\n",
    "    fx = x * inv_dx - base   # [n_particles] location in the grid\n",
    "    # Quadratic kernels  [http://mpm.graphics   Eqn. 123, with x=fx, fx-1,fx-2]\n",
    "    w = [0.5 * (1.5 - fx)**2, 0.75 - (fx - 1)**2, 0.5 * (fx - 0.5)**2]  # [n_particles] \n",
    "    F = (torch.eye(2, device=device, dtype=torch.float64)[None].expand(n_particles,2,2) + C * dt) @ F\n",
    "    # Hardening coefficient: snow gets harder when compressed\n",
    "    h = torch.maximum(torch.tensor(0.1, device=device), torch.minimum(torch.tensor(5, device=device), torch.exp(10 * (1.0 - Jp))))  #   Jp: [n_particles], plastic deformation\n",
    "    mask_material_0 = (material==0)\n",
    "    mask_material_1 = (material==1)\n",
    "    mask_material_2 = (material==2)\n",
    "    h[mask_material_2] = 0.3\n",
    "    mu, la = mu_0 * h, lambda_0 * h\n",
    "    length = len(F)\n",
    "    mu[mask_material_0] = 0.  # liquid\n",
    "\n",
    "    U, sig, V = torch.svd(F)\n",
    "    J = 1.0\n",
    "    for ii in range(2):\n",
    "        new_sig = sig[:, ii] # sig: [n_particles, 2]\n",
    "        new_sig[mask_material_1] = torch.minimum(torch.maximum(sig[mask_material_1, ii], torch.tensor(1 - 2.5e-2)), torch.tensor(1 + 4.5e-3))  # Plasticity\n",
    "        Jp = Jp * sig[:, ii] / new_sig\n",
    "        sig[:, ii] = new_sig\n",
    "        J = J * new_sig\n",
    "    F[mask_material_0] = torch.eye(2, device=device, dtype=torch.float64)[None].expand(len(mask_material_0),2,2) * J[:,None,None].sqrt()\n",
    "    sig_matrix = torch.eye(2, device=device, dtype=torch.float64)[None].expand(length,2,2) * sig[...,None]\n",
    "    F[mask_material_1] = U[mask_material_1] @ sig_matrix[mask_material_1] @ V[mask_material_1].transpose(1,2)\n",
    "\n",
    "    stress = 2 * mu[:,None,None] * (F - U @ V.transpose(1,2)) @ F.transpose(1,2\n",
    "            ) + torch.eye(2, device=device, dtype=torch.float64)[None].expand(length,2,2) * (la * J * (J - 1))[:,None,None]\n",
    "    stress = (-dt * p_vol * 4 * inv_dx * inv_dx) * stress\n",
    "    affine = stress + p_mass * C\n",
    "\n",
    "    # Deposition onto grid:\n",
    "    # Loop over 3x3 grid node neighborhood\n",
    "    grid_v_expand = expand_grid(grid_v, length=2)\n",
    "    grid_m_expand = expand_grid(grid_m, length=2)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            offset = torch.tensor([i, j], device=device, dtype=torch.float64)\n",
    "            dpos = (offset - fx) * dx\n",
    "            weight = w[i][:,0] * w[j][:,1]\n",
    "            base_core = base + offset.long()\n",
    "            try:\n",
    "                grid_v_expand[base_core[:,0],base_core[:,1]] += weight[:,None] * (p_mass * v + (affine @ dpos[:,:,None]).squeeze(-1))\n",
    "            except:\n",
    "                pdb.set_trace()\n",
    "            grid_m_expand[base_core[:,0],base_core[:,1]] += weight * p_mass\n",
    "\n",
    "    grid_v = shrink_grid(grid_v_expand, length=2)\n",
    "    grid_m = shrink_grid(grid_m_expand, length=2)\n",
    "\n",
    "    # Boundary condition:\n",
    "    rows, cols = torch.where(grid_m>epsilon)  # No need for epsilon here\n",
    "    grid_v[rows,cols] = (1 / grid_m[rows,cols][...,None]) * grid_v[rows,cols]  # Momentum to velocity\n",
    "    grid_v[rows,cols] += dt * gravity[None] * 30  # gravity\n",
    "    mask_mg0 = (grid_m>0)\n",
    "    mask_i0 = (grid_v[:,:,0] < 0) & torch.cat([torch.ones(3, n_grid, device=device, dtype=torch.float64), torch.zeros(n_grid-3, n_grid, device=device, dtype=torch.float64)], 0).bool()\n",
    "    mask_i1 = (grid_v[:,:,0] > 0) & torch.cat([torch.zeros(n_grid-3, n_grid, device=device, dtype=torch.float64), torch.ones(3, n_grid, device=device, dtype=torch.float64)], 0).bool()\n",
    "    mask_i  = mask_mg0 & (mask_i0 | mask_i1)\n",
    "    grid_v[...,0].masked_fill_(mask_i, 0)\n",
    "    mask_j0 = (grid_v[:,:,1] < 0) & torch.cat([torch.ones(n_grid, 3, device=device, dtype=torch.float64), torch.zeros(n_grid, n_grid-3, device=device, dtype=torch.float64)], 1).bool()\n",
    "    mask_j1 = (grid_v[:,:,1] > 0) & torch.cat([torch.zeros(n_grid, n_grid-3, device=device, dtype=torch.float64), torch.ones(n_grid, 3, device=device, dtype=torch.float64)], 1).bool()\n",
    "    mask_j  = mask_mg0 & (mask_j0 | mask_j1)\n",
    "    grid_v[...,1].masked_fill_(mask_j, 0)\n",
    "\n",
    "    # Grid to particle (G2P)\n",
    "    base = (x * inv_dx - 0.5).long()\n",
    "    fx = x * inv_dx - base.double()\n",
    "    w = [0.5 * (1.5 - fx)**2, 0.75 - (fx - 1.0)**2, 0.5 * (fx - 0.5)**2]\n",
    "    new_v = torch.zeros(length, 2, device=device, dtype=torch.float64)\n",
    "    new_C = torch.zeros(length, 2, 2, device=device, dtype=torch.float64)\n",
    "    grid_v_expand = expand_grid(grid_v, length=2)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            dpos = torch.tensor([i, j], device=device, dtype=torch.float64) - fx\n",
    "            base_core = base + torch.tensor([i, j], device=device)\n",
    "            g_v = grid_v_expand[base_core[:,0],base_core[:,1]]\n",
    "            weight = w[i][:,0] * w[j][:,1]\n",
    "            new_v += weight[...,None] * g_v\n",
    "            new_C += 4 * inv_dx * weight[:,None,None] * torch.einsum(\"bi,bj->bij\", g_v, dpos)\n",
    "    v, C = new_v, new_C\n",
    "    x += dt * v\n",
    "    return x, v, C, F, Jp, grid_m, grid_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2e7ff-fe2d-4f29-8a66-9c43662eec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trajectory(x, fluid, v_fluid, particle, v_particle, grid_m, grid_v, n_particles, epsilon=1e-8, is_gui=True):\n",
    "    # Reset other fields:\n",
    "    v, C, F, material, Jp = reset_other_fields(n_particles)\n",
    "    n_part_fluid = len(fluid)\n",
    "    n_part_particle = len(particle)\n",
    "\n",
    "    # Initialize data_record:\n",
    "    data_record = {}\n",
    "    data_record[\"x_fluid\"] = -np.ones((n_steps, fluid.shape[0], 2))\n",
    "    data_record[\"v_fluid\"] = -np.ones((n_steps, fluid.shape[0], 2))\n",
    "    data_record[\"x_particle\"] = -np.ones((n_steps, particle.shape[0], 2))\n",
    "    data_record[\"v_particle\"] = -np.ones((n_steps, particle.shape[0], 2))\n",
    "    data_record[\"grid_m\"] = -np.ones((n_steps, n_grid, n_grid))\n",
    "    data_record[\"grid_v\"] = -np.ones((n_steps, n_grid, n_grid, 2))\n",
    "    data_record[\"n_part_fluid\"] = fluid.shape[0]\n",
    "    data_record[\"n_part_particle\"] = particle.shape[0]\n",
    "    if is_gui:\n",
    "        res = (512, 512)\n",
    "        window = ti.ui.Window(\"Taichi MLS-MPM-128\", res=res, vsync=True)\n",
    "        canvas = window.get_canvas()\n",
    "        radius = 0.003\n",
    "        fluid_ti = ti.Vector.field(2, dtype=float, shape=n_part_fluid)\n",
    "        particle_ti = ti.Vector.field(2, dtype=float, shape=n_part_particle)\n",
    "\n",
    "    gravity = torch.tensor([0, -1], dtype=torch.float64, device=device)\n",
    "    k = 0\n",
    "    while True:\n",
    "        if is_gui:\n",
    "            if window.get_event(ti.ui.PRESS):\n",
    "                if window.event.key == 'r':\n",
    "                    x, v, C, F, material, Jp, fluid, particle, n_particles, n_part_fluid = reset_all()\n",
    "                elif window.event.key in [ti.ui.ESCAPE]:\n",
    "                    break\n",
    "        gravity[1] = -gravity_amp\n",
    "        for s in range(int(2e-3 // dt)):\n",
    "            x, v, C, F, Jp, grid_m, grid_v = substep_torch(x, v, C, F, Jp, gravity, epsilon=epsilon)\n",
    "        particle, v_particle, fluid, v_fluid = render(x, v, n_part_particle)\n",
    "        if is_gui:\n",
    "            fluid_ti.from_numpy(fluid)\n",
    "            particle_ti.from_numpy(particle)\n",
    "            canvas.set_background_color((0.067, 0.184, 0.255))\n",
    "            canvas.circles(fluid_ti, radius=radius, color=(0, 0.5, 0.5))\n",
    "            # # canvas.circles(jelly, radius=radius, color=(0.93, 0.33, 0.23))\n",
    "            canvas.circles(particle_ti, radius=radius, color=(0, 0.5, 0.5))\n",
    "            window.show()\n",
    "        data_record[\"x_fluid\"][k] = to_np_array(fluid)\n",
    "        data_record[\"v_fluid\"][k] = to_np_array(v_fluid)\n",
    "        data_record[\"x_particle\"][k] = to_np_array(particle)\n",
    "        data_record[\"v_particle\"][k] = to_np_array(v_particle)\n",
    "        data_record[\"grid_m\"][k] = to_np_array(grid_m)\n",
    "        data_record[\"grid_v\"][k] = to_np_array(grid_v)\n",
    "        k += 1\n",
    "        # if k % 10 == 0:\n",
    "        #     print(k)\n",
    "        if k >= n_steps:\n",
    "            break\n",
    "    return data_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0f582-cd60-42fc-953c-11805779f1c9",
   "metadata": {},
   "source": [
    "## Simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eac2b2a-5deb-4375-bc69-09c28db122dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "\n",
    "for ll in range(n_simu):\n",
    "    print(f\"Simu: {ll}\")\n",
    "\n",
    "    fluid_shape = sample_shape()\n",
    "    x_fluid = get_fluid(fluid_shape, n_part=max_n_part_fluid, height=height).astype(np.float64)\n",
    "    n_part_fluid = len(x_fluid)\n",
    "    rect_shape = sample_rect_shape()\n",
    "    x_particle = get_particles(rect_shape, n_part=n_part_particle).astype(np.float64)\n",
    "    print(\"fluid:\", n_part_fluid)\n",
    "    print(\"part:\", n_part_particle)\n",
    "\n",
    "    # # Remove too near:\n",
    "    if threshold > 0:\n",
    "        x_particle = remove_too_near(x_particle, threshold=threshold)\n",
    "        x_fluid = remove_too_near(x_fluid, threshold=threshold)\n",
    "        n_part_fluid = len(x_fluid)\n",
    "        print(\"fluid, after:\", n_part_fluid)\n",
    "        n_part_particle = len(x_particle)\n",
    "        print(\"part, after:\", n_part_particle)\n",
    "\n",
    "    if is_particle:\n",
    "        x_combine = np.concatenate([x_particle, x_fluid]).astype(np.float64)\n",
    "        n_particles = n_part_fluid + n_part_particle\n",
    "    else:\n",
    "        n_part_particle = 1\n",
    "        x_particle = np.array([[0.001, 0.001]]).astype(np.float64)\n",
    "        x_combine = np.concatenate([x_particle, x_fluid]).astype(np.float64)\n",
    "        n_particles = n_part_fluid + n_part_particle\n",
    "\n",
    "    data_dirname = f\"taichi_hybrid_simu_{n_simu}_step_{n_steps}_h_{height}_fluid_{max_n_part_fluid}_part_{n_part_particle}_g_{gravity_amp}_thresh_{threshold}\"\n",
    "\n",
    "    x = torch.tensor(x_combine, device=device, dtype=torch.float64)\n",
    "    fluid = torch.tensor(x_fluid, device=device, dtype=torch.float64)\n",
    "    particle = torch.tensor(x_particle, device=device, dtype=torch.float64)\n",
    "    v_fluid = torch.zeros(n_part_fluid, 2, device=device, dtype=torch.float64)\n",
    "    v_particle = torch.zeros(n_part_particle, 2, device=device, dtype=torch.float64)\n",
    "\n",
    "    # Initialize up other fields:\n",
    "    v = torch.zeros(n_particles, 2, device=device, dtype=torch.float64)  # velocity\n",
    "    C = torch.zeros(n_particles, 2, 2, device=device, dtype=torch.float64)  # affine velocity field\n",
    "    F = torch.zeros(n_particles, 2, 2, device=device, dtype=torch.float64)  # deformation gradient\n",
    "    material = torch.zeros(n_particles, device=device).long()  # material id\n",
    "    Jp = torch.zeros(n_particles, device=device, dtype=torch.float64)  # plastic deformation\n",
    "\n",
    "    # Get trajectory:\n",
    "    data_record = get_trajectory(\n",
    "        x, fluid, v_fluid, particle, v_particle, grid_m, grid_v, n_particles, epsilon=args.epsilon, is_gui=is_gui)\n",
    "    data_record[\"rect_shape\"] = rect_shape\n",
    "    data_record[\"fluid_shape\"] = fluid_shape\n",
    "\n",
    "    if args.is_save:\n",
    "        data_dirname = f\"taichi_hybrid_simu_{n_simu}_step_{n_steps}_h_{height}_fluid_{max_n_part_fluid}_part_{particle.shape[0]}_g_{gravity_amp}_thresh_{threshold}\"\n",
    "        data_filename = data_dirname + \"/sim_{:06d}.p\".format(ll)\n",
    "        make_dir(data_filename)\n",
    "        pickle.dump(data_record, open(data_filename, \"wb\"))\n",
    "    del x, v, fluid, particle, v_fluid, v_particle, C, F, material, Jp, data_record\n",
    "    gc.collect()\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
